tensorflow version: 2.5.0
device: cpu
target domain subjects: ['P_14_hunan', 'P_20_xuanweicheng', 'P_23_wangjinhong', 'P_24_liziqing']
test subjects id names: ['P_14_hunan']
Model selection: DANN
source_loader len: 333, target_train_loader len:270, n_batch: 270
> /home/sun/workspace/PythonProject/DataAnalysis/P6/transfer_learning_for_droplanding/DeepDA/main.py(284)train()
-> optimizer.zero_grad()
(Pdb) 279  	                print('only transfer loss: ', transfer_loss)
280  	            else:
281  	                loss = args.regression_loss_weight*reg_loss + args.transfer_loss_weight * transfer_loss
282  	            pdb.set_trace()
283  	
284  ->	            optimizer.zero_grad()
285  	            '''
286  	            print("\n===========开始迭代========")
287  	            for name, params in model.named_parameters():
288  	                print('--> name: ', name)
289  	                print('--> param: ', params)
(Pdb) 265  	        train_loss_total = utils.AverageMeter()
266  	
267  	        if max(len_target_loader, len_source_loader) != 0:
268  	            iter_source, iter_target = iter(source_loader), iter(target_train_loader)
269  	
270  	        for _ in range(n_batch):
271  	            data_source, label_source = next(iter_source) # .next()
272  	            data_target, label_target = next(iter_target) # .next()
273  	            data_source, label_source = data_source.to(args.device), label_source.to(args.device)
274  	            data_target, label_target = data_target.to(args.device), label_target.to(args.device)
275  	
(Pdb) 276  	            reg_loss, transfer_loss = model(data_source, data_target, label_source, label_target)
277  	            if(transfer_loss.item()<0.01):
278  	                loss = args.transfer_loss_weight * transfer_loss
279  	                print('only transfer loss: ', transfer_loss)
280  	            else:
281  	                loss = args.regression_loss_weight*reg_loss + args.transfer_loss_weight * transfer_loss
282  	            pdb.set_trace()
283  	
284  ->	            optimizer.zero_grad()
285  	            '''
286  	            print("\n===========开始迭代========")
(Pdb) 