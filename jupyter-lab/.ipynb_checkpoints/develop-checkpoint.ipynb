{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f151725-83d7-4eb9-859b-385b9e8e8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a46b4-fb1c-458a-af33-3f9c2704eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## %load ./../rnn_model.py\n",
    "#!/usr/bin/env python\n",
    "'''\n",
    " Import necessary packages\n",
    "\n",
    "'''\n",
    "import tensorflow as tf\n",
    "# set hardware config\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "\n",
    "# set gpu memory grouth automatically\n",
    "#for gpu in gpus:\n",
    "#    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "if(gpus!=[]):\n",
    "    # set virtal gpu/ logical gpu, create four logical gpu from a physical gpu (gpus[0])\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072),\n",
    "        tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072),\n",
    "        tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072),\n",
    "        tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)\n",
    "        ]\n",
    "        )\n",
    "\n",
    "logical_cpus = tf.config.experimental.list_logical_devices(device_type='CPU')\n",
    "logical_gpus = tf.config.experimental.list_logical_devices(device_type='GPU')\n",
    "print('physical cpus and gpus: ',cpus, gpus)\n",
    "print('physical cpus number: ', len(cpus))\n",
    "print('physical cpgs number: ', len(gpus))\n",
    "print('logical cpus and gpus: ',logical_cpus, logical_gpus)\n",
    "print('logical cpgs number: ', len(logical_gpus))\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import h5py\n",
    "print(\"tensorflow version:\",tf.__version__)\n",
    "import vicon_imu_data_process.process_rawdata as pro_rd\n",
    "import estimation_assessment.scores as es_as\n",
    "import estimation_assessment.visualization as es_vl\n",
    "\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import re\n",
    "import json\n",
    "\n",
    "from vicon_imu_data_process.const import FEATURES_FIELDS, LABELS_FIELDS, DATA_PATH, TRAIN_USED_TRIALS\n",
    "from vicon_imu_data_process.const import DROPLANDING_PERIOD, RESULTS_PATH\n",
    "from vicon_imu_data_process import const\n",
    "from vicon_imu_data_process.dataset import *\n",
    "\n",
    "\n",
    "from estimation_models.rnn_models import *\n",
    "from estimation_study import *\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "import time as localtimepkg\n",
    "\n",
    "#subject_infos = pd.read_csv(os.path.join(DATA_PATH, 'subject_info.csv'), index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe58d7c-8b04-4b59-9e6b-998479125dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function investigate the estimation metrics by \n",
    "testing different sensor configurations and model LSTM layer size\n",
    "\n",
    "'''\n",
    "\n",
    "def integrative_investigation(investigation_variables):\n",
    "\n",
    "    sensor_configurations = investigation_variables['sensor_configurations']\n",
    "    lstm_units  = investigation_variables['lstm_units']\n",
    "    combination_investigation_info = []\n",
    "    #2) train and test model\n",
    "    \n",
    "    #i) sensor configurations\n",
    "    for sensor_configuration_name, sensor_list in sensor_configurations.items():\n",
    "        # features fields based on sensors\n",
    "        features_fields = const.extract_imu_fields(sensor_list, const.ACC_GYRO_FIELDS)\n",
    "        \n",
    "        # init hyper params\n",
    "        hyperparams = initParameters(labels_names=LABELS_FIELDS, features_names=features_fields)\n",
    "        \n",
    "        #ii) model size configuations\n",
    "        for lstm_unit in lstm_units:\n",
    "            hyperparams['lstm_units'] = lstm_unit\n",
    "            hyperparams['sensor_configurations'] = sensor_configuration_name\n",
    "            \n",
    "            # train and test model\n",
    "            print(\"#**************************************************************************#\")\n",
    "            print(\"Sensor configuration: {}; LSTM size: {}\".format(sensor_configuration_name, lstm_unit))\n",
    "            \n",
    "            # do training and testing\n",
    "            training_testing_folders, xy_test, scaler =  train_test_loops(hyperparams, fold_number=20)# model traning\n",
    "            \n",
    "            # list testing folders \n",
    "            combination_investigation_info.append((sensor_configuration_name, str(lstm_unit), training_testing_folders))\n",
    "\n",
    "    #3) create folders to save testing folders\n",
    "    combination_investigation_testing_folders = os.path.join(RESULTS_PATH,\"investigation\",\n",
    "                                         str(localtimepkg.strftime(\"%Y-%m-%d\",localtimepkg.localtime())),\n",
    "                                         str(localtimepkg.strftime(\"%H%M%S\", localtimepkg.localtime())))\n",
    "    if(not os.path.exists(combination_investigation_testing_folders)):\n",
    "        os.makedirs(combination_investigation_testing_folders)\n",
    "    \n",
    "    #4) save testing folders\n",
    "    combination_testing_folders = os.path.join(combination_investigation_testing_folders,\"testing_result_folders.txt\")\n",
    "    if(os.path.exists(combination_testing_folders)==False):\n",
    "        with open(combination_testing_folders,'a') as f:\n",
    "            for (sensor_config, lstm_unit, train_test_results) in combination_investigation_info:\n",
    "                for idx, testing_folder in enumerate(train_test_results[\"testing_folder\"]): # in a loops which has many train and test loop\n",
    "                    f.write(sensor_config + '\\t'+ lstm_unit + '\\t' + testing_folder + '\\n') # save configs\n",
    "                                                    \n",
    "    print(\"INESTIGATION DONE!\")\n",
    "    return combination_testing_folders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185a987-dfee-4b7e-b84d-1ae54bd3795b",
   "metadata": {},
   "source": [
    "## Perform investigation by training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439072b-7c6b-4a0d-904a-f0a14ee37bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1) The variables that are needed to be investigate\n",
    "investigation_variables={\n",
    "    \"sensor_configurations\":\n",
    "                            {\n",
    "                               'F': ['L_FOOT'],\n",
    "                               'S': ['L_SHANK'],\n",
    "                               'T': ['L_THIGH'],\n",
    "                               'W': ['WAIST'],\n",
    "                               'C': ['CHEST'],\n",
    "                                \n",
    "                               'FS': ['L_FOOT','L_SHANK'],\n",
    "                               'FT': ['L_FOOT','L_THIGH'],\n",
    "                               'FW': ['L_FOOT','WAIST'],\n",
    "                               'FC': ['L_FOOT','CHEST'],\n",
    "                               'ST': ['L_SHANK','L_THIGH'],\n",
    "                               'SW': ['L_SHANK','WAIST'],\n",
    "                               'SC': ['L_SHANK','CHEST'],\n",
    "                               'TW': ['L_THIGH','WAIST'], \n",
    "                               'TC': ['L_THIGH', 'CHEST'],\n",
    "                               'WC': ['WAIST', 'CHEST'],\n",
    "                               \n",
    "                                \n",
    "                               'FST': ['L_FOOT','L_SHANK','L_THIGH'], \n",
    "                               'FSW': ['L_FOOT','L_SHANK','WAIST'],\n",
    "                               'FSC': ['L_FOOT','L_SHANK','CHEST'],\n",
    "                                \n",
    "                               'FTW': ['L_FOOT','L_THIGH','WAIST'],\n",
    "                               'FTC': ['L_FOOT','L_THIGH','CHEST'],\n",
    "                               \n",
    "                               'FWC': ['L_FOOT','WAIST', 'CHEST'],\n",
    "                                \n",
    "                               'STW': ['L_SHANK','L_THIGH','WAIST' ],\n",
    "                               'STC': ['L_SHANK','L_THIGH','CHEST' ],\n",
    "                               'SWC': ['L_SHANK','WAIST','CHEST' ],\n",
    "                               'TWC': ['L_THIGH','WAIST', 'CHEST'],\n",
    "                                \n",
    "                               'FSTW': ['L_FOOT','L_SHANK','L_THIGH','WAIST'], \n",
    "                               'FSTC': ['L_FOOT','L_SHANK','L_THIGH','CHEST'], \n",
    "                               'FSWC': ['L_FOOT','L_SHANK','WAIST', 'CHEST'],\n",
    "                               'FTWC': ['L_FOOT','L_THIGH','WAIST', 'CHEST'],\n",
    "                               'STWC': ['L_SHANK','L_THIGH','WAIST', 'CHEST'],\n",
    "                                \n",
    "                               'FSTWC': ['L_FOOT','L_SHANK','L_THIGH','WAIST', 'CHEST']\n",
    "                              },\n",
    "    \n",
    "    \"sensor_configurations\":\n",
    "                            {                              \n",
    "                               'FSTC': ['L_FOOT','L_SHANK','L_THIGH','CHEST']\n",
    "                              },\n",
    "    #\"sensor_configurations\": {'FSTWC': ['L_FOOT','L_SHANK','L_THIGH','WAIST', 'CHEST']},\n",
    "    #\"lstm_units\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
    "    #\"lstm_units\": [15, 20, 25, 30, 35]\n",
    "    \"lstm_units\": [35]\n",
    "}\n",
    "\n",
    "\n",
    "# investigate model\n",
    "combination_investigation_results = integrative_investigation(investigation_variables)\n",
    "\n",
    "print(combination_investigation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244f838-faf3-4295-94bf-e4c644527248",
   "metadata": {},
   "source": [
    "## exit machine and save environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694839d-2f87-48f3-a93b-531da19b7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"export $(cat /proc/1/environ |tr '\\\\0' '\\\\n' | grep MATCLOUD_CANCELTOKEN)&&/public/script/matncli node cancel -url https://matpool.com/api/public/node -save -name suntao_env\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
